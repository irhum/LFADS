from typing import Optional

import haiku as hk
import jax
import jax.numpy as jnp

from .recurrent import ZeroOneInitializer


class NormedLinear(hk.Module):
  def __init__(self, output_size:int, name: Optional[str]=None):
      super().__init__(name=name)
      self.output_size = output_size
  
  def __call__(self, inputs) -> jnp.ndarray:
    input_size = inputs.shape[-1]
    w_init = hk.initializers.TruncatedNormal(stddev=1./input_size)

    w = hk.get_parameter(name="w", shape=[input_size, self.output_size], 
                        dtype=inputs.dtype, init=w_init)
    
    norm_w = w / jnp.linalg.norm(w, axis=0)
    return jnp.dot(inputs, norm_w)

class BiDirEncoder(hk.Module):
  """Passes the input firing rates through two GRUs, one operating forward
and one backward in time. Returns their final outputs, concatenated on the
feature dimension."""

  def __init__(self, hidden_dim=64, generator_dim=64):
    super().__init__()
    self.hidden_dim = hidden_dim
    self.generator_dim = generator_dim
  
  def get_init_states(self):
    f_init = hk.get_parameter("forward_init", shape=(self.hidden_dim,), init=jnp.zeros)
    b_init = hk.get_parameter("backward_init", shape=(self.hidden_dim,), init=jnp.zeros) 

    return f_init, b_init
  
  def repeat_init(self, init, batch_size):
    return jnp.repeat(init[None, :], repeats=batch_size, axis=0)

  def __call__(self, seqs, drop_rate=0.02):
    batch_size = seqs.shape[1]
    seqs = hk.dropout(hk.next_rng_key(), drop_rate, seqs)

    f_core = hk.GRU(self.hidden_dim, name="forward_gru", b_init=ZeroOneInitializer())
    b_core = hk.GRU(self.hidden_dim, name="backward_gru", b_init=ZeroOneInitializer())

    f_init, b_init = self.get_init_states()

    fouts, _ = hk.dynamic_unroll(f_core, seqs, self.repeat_init(f_init, batch_size))
    bouts, _ = hk.dynamic_unroll(b_core, jnp.flip(seqs, axis=0), self.repeat_init(b_init, batch_size))

    encoded = jnp.concatenate([fouts[-1], bouts[-1]], axis=1)
    encoded = hk.dropout(hk.next_rng_key(), drop_rate, encoded)

    mean = hk.Linear(self.generator_dim)(encoded)
    stddev = jnp.exp(0.5 * hk.Linear(self.generator_dim)(encoded))

    return mean, stddev

class RatesGeneratorAutonomous(hk.Module):
  """Uses the starting point for the generator (stochastically sampled 
  from the mean and standard deviation generated by BiDirEncoder. Autonomous
  version, that is, assumes there are no inputs to be inferred, the spike trains
  are produced purely by dynamics of the system"""

  def __init__(self, generator_dim=64, factors_dim=3, rates_dim=30):
    super().__init__()

    self.generator_dim = generator_dim
    self.factors_dim = factors_dim
    self.rates_dim = rates_dim

  def __call__(self, g_inits, steps=1000, drop_rate=0.02):
    g_core = hk.GRU(self.generator_dim, name="generator_gru", b_init=ZeroOneInitializer())

    dummy_u = jnp.zeros(shape=[steps] + list(g_inits.shape))
    g_outs, _ = hk.dynamic_unroll(g_core, dummy_u, g_inits)

    # this weight matrix requires normalization
    factors = hk.BatchApply(NormedLinear(self.factors_dim))(g_outs)
    rates = jnp.exp(hk.BatchApply(hk.Linear(self.rates_dim))(factors))

    return factors, rates

class LFADSAutonomous(hk.Module):
  """Full automous LFADS model (Fig. 1 from the Nature paper). Encodes
  input into start point for generator, which is evolved according to the 
  learnt neural dynamics. Assumes there are no inferred inputs i.e. spike 
  trains are produced purely by the dynamics of the system"""
  def __init__(self, hidden_dim=64, generator_dim=64, factors_dim=3, rates_dim=30):
    super().__init__()

    self.hidden_dim = hidden_dim
    self.generator_dim = generator_dim
    self.factors_dim = factors_dim
    self.rates_dim = rates_dim

  def __call__(self, seqs, drop_rate=0.05):
    mean, stddev = BiDirEncoder(self.hidden_dim, self.generator_dim)(seqs, drop_rate=drop_rate)
    sample_g = mean + stddev * jax.random.normal(hk.next_rng_key(), shape=stddev.shape)
    
    steps = seqs.shape[0]
    factors, rates = RatesGeneratorAutonomous(self.generator_dim, self.factors_dim, self.rates_dim)(sample_g, steps, drop_rate)

    return mean, stddev, factors, rates
